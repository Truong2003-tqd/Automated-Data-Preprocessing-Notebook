{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cba5f628",
   "metadata": {},
   "source": [
    "# Setup & Data Import"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e750855",
   "metadata": {},
   "source": [
    "## Setup Global Configs and Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c25e1ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SETUP & IMPORT\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "from pathlib import Path\n",
    "from scipy import stats\n",
    "import itertools\n",
    "import re\n",
    "import missingno as msno\n",
    "\n",
    "# Display options for clarity\n",
    "pd.set_option('display.width', 160)\n",
    "pd.set_option('display.max_columns', 50)\n",
    "pd.set_option('display.float_format', lambda v: f\"{v:,.4f}\")\n",
    "\n",
    "# Set visual themes\n",
    "sns.set_theme(style='whitegrid', context='notebook', font_scale=1.05)\n",
    "plt.rcParams['figure.figsize'] = (10, 5)\n",
    "plt.rcParams['axes.titlesize'] = 14\n",
    "plt.rcParams['axes.labelsize'] = 12\n",
    "plt.rcParams['axes.facecolor'] = 'white'\n",
    "plt.rcParams['figure.facecolor'] = 'white'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "049cad19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Define Paths ---\n",
    "salary_path = Path('Salary_Data.csv')\n",
    "survey_path = Path('survey_respondents_info.csv')\n",
    "superstore_path = Path('Superstore 2023.csv')\n",
    "\n",
    "# --- Validate File Existence ---\n",
    "for path in [salary_path, survey_path, superstore_path]:\n",
    "    if not path.exists():\n",
    "        raise FileNotFoundError(f\"❌ File not found: {path.resolve()}\")\n",
    "\n",
    "# --- Load with Delimiter Fallback ---\n",
    "def load_csv_safely(path):\n",
    "    try:\n",
    "        return pd.read_csv(path, sep=',', engine='python')\n",
    "    except Exception:\n",
    "        print(f\"⚠️ Failed with ',' — retrying with ';' for {path.name}...\")\n",
    "        return pd.read_csv(path, sep=';', engine='python')\n",
    "\n",
    "# --- Load Both Datasets ---\n",
    "salary_df = load_csv_safely(salary_path)\n",
    "survey_df = load_csv_safely(survey_path)\n",
    "superstore_df = load_csv_safely(superstore_path)\n",
    "\n",
    "print(f\"✅ Salary_Data loaded: {salary_df.shape[0]:,} rows × {salary_df.shape[1]} columns\")\n",
    "print(salary_df.info())\n",
    "display(salary_df.head())\n",
    "\n",
    "print(f\"✅ Survey_Respondents_Info loaded: {survey_df.shape[0]:,} rows × {survey_df.shape[1]} columns\")\n",
    "print(survey_df.info())\n",
    "display(survey_df.head())\n",
    "\n",
    "print(f\"✅ Superstore_Data loaded: {superstore_df.shape[0]:,} rows × {superstore_df.shape[1]} columns\")\n",
    "print(superstore_df.info())\n",
    "display(superstore_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3957cf21",
   "metadata": {},
   "source": [
    "## Define Necessary Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b734608b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to split CamelCase while keeping acronyms intact\n",
    "def split_camel_case_keep_acronyms(name):\n",
    "    \"\"\"\n",
    "    Convert CamelCase to Snake_Case while keeping acronyms intact.\n",
    "    \n",
    "    Examples:\n",
    "    - 'MostFavourite' -> 'Most_Favourite'\n",
    "    - 'CustomerMPIValue' -> 'Customer_MPI_Value'\n",
    "    - 'NPSScore' -> 'NPS_Score'\n",
    "    \"\"\"\n",
    "    # Insert underscore between:\n",
    "    #   1. a lowercase letter and uppercase letter (e.g., tM -> t_M)\n",
    "    #   2. but NOT between consecutive uppercase letters (e.g., MPI stays MPI)\n",
    "    return re.sub(r'(?<=[a-z])(?=[A-Z])', '_', name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5edc81fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function to check ID uniqueness\n",
    "def check_id_uniqueness(df, id_column='id'):\n",
    "    \"\"\"\n",
    "    Check if the specified ID column in a DataFrame contains unique values.\n",
    "    Prints duplicate IDs and their counts if any are found.\n",
    "    \"\"\"\n",
    "\n",
    "    \"\"\"\n",
    "    Steps:\n",
    "    1. Count frequency of each ID.\n",
    "    2. If all frequencies are 1, IDs are unique.\n",
    "    3. If any frequency > 1, there are duplicate IDs.\n",
    "    4. Print duplicate IDs with their counts.\n",
    "    \"\"\"\n",
    "    # Check if the ID column exists\n",
    "    if id_column not in df.columns:\n",
    "        print(f\"❌ Column '{id_column}' not found in DataFrame, try a correct column name.\")\n",
    "        return\n",
    "\n",
    "    # Step 1: Count frequency of each ID\n",
    "    id_counts = df[id_column].value_counts()\n",
    "\n",
    "    # Step 2: Check if all IDs are unique\n",
    "    if (id_counts == 1).all():\n",
    "        print(\"✅ All IDs are unique.\")\n",
    "    else:\n",
    "        print(\"❌ Duplicate IDs found!\")\n",
    "\n",
    "        # Step 3: Filter IDs where frequency > 1\n",
    "        duplicates = id_counts[id_counts > 1]\n",
    "\n",
    "        # Step 4: Print duplicate IDs and their counts\n",
    "        print(\"\\nDuplicated IDs and their counts:\")\n",
    "        print(duplicates)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d75b5f2",
   "metadata": {},
   "source": [
    "## Change Columns Formatting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e42bcd83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check column names\n",
    "dfs = [\n",
    "    salary_df,\n",
    "    survey_df,\n",
    "    superstore_df\n",
    "]\n",
    "\n",
    "for df in dfs:\n",
    "    print(list(df.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2409ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace # with _ in column names\n",
    "for df in dfs:\n",
    "    df.columns = df.columns.str.replace('#', '_', regex=False)\n",
    "    print(list(df.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "866bdf53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split CamelCase while preserving acronyms\n",
    "for df in dfs:\n",
    "    df.columns = [split_camel_case_keep_acronyms(col) for col in df.columns]\n",
    "    print(list(df.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "183f29b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace ' ' with _ in column names\n",
    "for df in dfs:\n",
    "    df.columns = df.columns.str.replace(' ', '_', regex=False)\n",
    "    print(list(df.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d1dc4c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert all column names to lowercase\n",
    "for df in dfs:\n",
    "    df.columns = df.columns.str.lower()\n",
    "    print(list(df.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d5b227d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check column names after formatting\n",
    "for df in dfs:\n",
    "    print(list(df.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04fad319",
   "metadata": {},
   "source": [
    "# Dataframe 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e985b760",
   "metadata": {},
   "source": [
    "## Select Dataset and Handle Grammar Errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dec87200",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select dataset to analyze\n",
    "current_df = superstore_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dcbf081",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print column names\n",
    "print(\"Data columns:\", list(current_df.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8f6260c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check unique values to identity grammar and data issues\n",
    "for column_name in current_df.columns:\n",
    "    print(f\"Unique values in column '{column_name}':\")\n",
    "    print(current_df[column_name].unique())\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbebb04b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix grammar issues manually if any\n",
    "replacement_dict = {}           # Add replacements as needed\n",
    "target_col = []                 # Only apply one column at a time\n",
    "\n",
    "# Dictionary is not blank, so apply replacements\n",
    "if len(replacement_dict) == 0 or len(target_col) == 0:\n",
    "    print(\"ℹ️ replacement_dict and target_col are empty — no replacements applied.\")\n",
    "else:\n",
    "    for col in target_col:\n",
    "        if col in current_df.columns:\n",
    "            current_df[col] = current_df[col].replace(replacement_dict)\n",
    "            print(\"✅ Replacements applied successfully to column:\", col)\n",
    "            print(f\"Unique values in '{col}' after replacements:\", current_df[col].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "504fcc08",
   "metadata": {},
   "source": [
    "## Define Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f331123e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define columns\n",
    "categorical_cols = ['ship_mode', 'segment', 'country/region', 'city', 'state', 'region', 'category', 'sub-category'] # Change respectively to your dataset\n",
    "numerical_cols = ['sales', 'quantity', 'discount', 'profit']   # Change respectively to your dataset\n",
    "date_cols = ['order_date', 'ship_date']  # Add date columns if any\n",
    "data_cols = current_df.columns.to_list()\n",
    "\n",
    "# Validate presence of expected columns\n",
    "missing_expected = [c for c in categorical_cols + numerical_cols if c not in current_df.columns]\n",
    "if missing_expected:\n",
    "    print(\"⚠️ Warning: These expected columns are missing in the dataset:\", missing_expected)\n",
    "\n",
    "# Coerce categorical columns\n",
    "for col in categorical_cols:\n",
    "    if col in current_df.columns:\n",
    "        current_df[col] = current_df[col].astype('category')\n",
    "\n",
    "# Attempt to convert numerical columns robustly\n",
    "for col in numerical_cols:\n",
    "    if col in current_df.columns:\n",
    "        # Strip common formatting issues then coerce\n",
    "        current_df[col] = (current_df[col]\n",
    "                   .astype(str)\n",
    "                   .str.replace('$', '', regex=False)\n",
    "                   .str.replace(',', '', regex=False)\n",
    "                   .str.strip())\n",
    "        current_df[col] = pd.to_numeric(current_df[col])\n",
    "\n",
    "# Convert date columns\n",
    "for col in date_cols:\n",
    "    if col in current_df.columns:\n",
    "        # Strip common formatting issues then parse dates\n",
    "        current_df[col] = (current_df[col]\n",
    "                     .astype(str)\n",
    "                     .str.replace('/', '-', regex=False)\n",
    "                     .str.replace('.', '-', regex=False)\n",
    "                     .str.replace('\\\\', '-', regex=False)\n",
    "                     # Trim timestamp if present\n",
    "                     .str.split(' ').str[0]\n",
    "                     .str.strip())\n",
    "        current_df[col] = pd.to_datetime(current_df[col], format='%d-%m-%Y').dt.strftime('%m/%d/%Y')\n",
    "\n",
    "print(\"\\nDataFrame info():\")\n",
    "print(current_df.info())\n",
    "\n",
    "display(current_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97a47a6a",
   "metadata": {},
   "source": [
    "## Data Quality Assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "143a9dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check uniqueness of 'id' column \n",
    "check_id_uniqueness(current_df, id_column='row_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17dfba32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Descriptive statistics (numeric)\n",
    "print(\"\\nDescriptive statistics (numeric):\")\n",
    "display(current_df.describe().round(2))\n",
    "\n",
    "# Check duplicate rows\n",
    "duplicate_rows = int(current_df.duplicated().sum())\n",
    "print(f\"Duplicate rows: {duplicate_rows:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a03a8621",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Missingness summary\n",
    "miss_summary = (\n",
    "    current_df.isna()\n",
    "    .sum()\n",
    "    .rename(\"Number of Missing\")\n",
    "    .to_frame()\n",
    ")\n",
    "miss_summary[\"Percentage of Missing\"] = (miss_summary[\"Number of Missing\"] / len(current_df) * 100).round(2)\n",
    "miss_summary = miss_summary.rename_axis(\"Column\")\n",
    "print(\"Summary Table of Missing Values:\")\n",
    "display(miss_summary.sort_values(\"Number of Missing\", ascending=False))\n",
    "\n",
    "# Summarize missing count\n",
    "msno.bar(current_df, figsize=(16, 5), color='steelblue')\n",
    "plt.title(\"Missing Values by Column\")\n",
    "plt.show()\n",
    "\n",
    "# Find missing pattern\n",
    "msno.heatmap(current_df, figsize=(8, 4))\n",
    "plt.title(\"Correlation of Missingness Between Columns\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b18d3a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find missing pattern\n",
    "target_col = []\n",
    "group_col = []\n",
    "for col in group_col:\n",
    "    na_rate = current_df.groupby(col)[target_col].apply(lambda x: x.isna().mean())\n",
    "    #print(\"\\n\")\n",
    "    #print(na_rate)\n",
    "\n",
    "    plt.figure(figsize=(min(16, 2 + 0.5*na_rate.shape[0]), 0.5*na_rate.shape[0] + 2))\n",
    "    sns.heatmap(na_rate, annot=True, fmt=\".1%\", cmap=\"YlOrRd\", cbar=True)\n",
    "    plt.title(f\"Missing-rate heatmap by `{col}`\")\n",
    "    plt.xlabel(\"Target numeric columns\")\n",
    "    plt.ylabel(col)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d16c882",
   "metadata": {},
   "source": [
    "## Handle Missing Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd91cc10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Median imputation for numerical columns by group\n",
    "target_col = []             # Apply one column at a time\n",
    "group_col = []              # Grouping columns to calculate median\n",
    "imputation_method = 'mean'  # Options: 'mode', 'mean', 'median'\n",
    "\n",
    "if len(target_col) == 0 or len(group_col) == 0:\n",
    "    print(\"ℹ️ target_col and group_col are empty — no replacements applied.\")\n",
    "else:\n",
    "    for col in target_col:\n",
    "        if col not in current_df.columns:\n",
    "            print(f\"❌ Column '{col}' not found — skipping.\")\n",
    "        else:\n",
    "            # Select imputation method\n",
    "            if imputation_method == 'mode':\n",
    "                imputed_series = current_df.groupby(group_col, dropna=True, observed=True)[col].transform(lambda s: s.mode().iloc[0] if not s.mode().empty else np.nan)\n",
    "            elif imputation_method == 'mean':\n",
    "                imputed_series = current_df.groupby(group_col, dropna=True, observed=True)[col].transform('mean')\n",
    "            elif imputation_method == 'median':\n",
    "                imputed_series = current_df.groupby(group_col, dropna=True, observed=True)[col].transform('median')\n",
    "            else:\n",
    "                print(\"⚠️ Invalid imputation_method. Choose from 'mode', 'mean', or 'median'.\")\n",
    "                break\n",
    "\n",
    "            # --- Create new imputed column ---\n",
    "            out_col = f\"{col}_imputed\"\n",
    "            current_df[out_col] = current_df[col].fillna(imputed_series)\n",
    "\n",
    "            # --- Report results ---\n",
    "            before = int(current_df[col].isna().sum())\n",
    "            after  = int(current_df[out_col].isna().sum())\n",
    "            print(f\"✅ '{col}' imputed using {imputation_method} per group ({', '.join(group_col)}).\")\n",
    "            print(f\"   Missing before: {before}, after: {after}\")\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe699405",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overwrite original column with imputed values if needed\n",
    "for col in target_col:\n",
    "    out_col = f\"{col}_imputed\"\n",
    "    if out_col in current_df.columns:\n",
    "        current_df[col] = current_df[out_col]\n",
    "        current_df.drop(columns=[out_col], inplace=True)\n",
    "        print(f\"✅ Overwrote '{col}' with imputed values and dropped '{out_col}'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f8c3271",
   "metadata": {},
   "source": [
    "## Outlier Detection\n",
    "Outliers are identified by IQR because IQR method is robust to outliers. In real world, data is commonly non-normal and skewed, making z-score methods less precise in detecting outliers.\n",
    "This cell analyzes `current_df` (DataFrame 1) for:\n",
    "- Outlier detection using both IQR (1.5*IQR)\n",
    "- Visual diagnostics: boxplots + pairwise scatter vs target-like numeric columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4af5884a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OUTLIER DETECTION\n",
    "# Calculate IQR for numerical columns\n",
    "Q1 = current_df[numerical_cols].quantile(0.25)\n",
    "Q3 = current_df[numerical_cols].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "# Identify outliers using IQR\n",
    "outlier_condition = (current_df[numerical_cols] < (Q1 - 1.5 * IQR)) | (current_df[numerical_cols] > (Q3 + 1.5 * IQR))\n",
    "outliers_iqr = (outlier_condition).sum()\n",
    "outliers_iqr = outliers_iqr.rename(\"IQR Outliers\").to_frame().sort_values(by=\"IQR Outliers\", ascending=False)\n",
    "print(\"Number of outliers detected by IQR:\")\n",
    "print(outliers_iqr)\n",
    "print('-'*50)\n",
    "\n",
    "# Outlier marking columns if outliers exists\n",
    "for col in numerical_cols:\n",
    "    if outliers_iqr.loc[col, \"IQR Outliers\"] > 0:\n",
    "        current_df[f'{col}_outlier'] = outlier_condition[col]\n",
    "\n",
    "# Visualize distributions with boxplots\n",
    "\n",
    "plt.figure(figsize=(min(16, 4*len(numerical_cols)), 4*len(numerical_cols)))\n",
    "for i, col in enumerate(numerical_cols, 1):\n",
    "\n",
    "    # Capitalize column names for display\n",
    "    col_display = str.capitalize(col)\n",
    "    \n",
    "    plt.subplot(len(numerical_cols), 3, i)\n",
    "    sns.boxplot(x=current_df[col], color='steelblue')\n",
    "    plt.title(f'Boxplot of {col_display}')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff248465",
   "metadata": {},
   "source": [
    "## Univariate Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37b69fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bar chart for categorical columns (show 15 most frequent categories)\n",
    "\n",
    "# Exclude columns if needed\n",
    "exclude_cat = ['country/region']  \n",
    "used_cat = [col for col in categorical_cols if col not in exclude_cat]\n",
    "\n",
    "# Set up plot grid\n",
    "cols = 2\n",
    "rows = int(np.ceil(len(used_cat) / cols))\n",
    "plt.figure(figsize=(14, 4 * rows))\n",
    "\n",
    "for i, col in enumerate(used_cat, 1):\n",
    "    plt.subplot(rows, cols, i)\n",
    "    ax = sns.countplot(\n",
    "        data=current_df,\n",
    "        y=col,\n",
    "        order=current_df[col].value_counts().index[:15]\n",
    "    )\n",
    "\n",
    "    # --- Add data labels ---\n",
    "    for container in ax.containers:\n",
    "        ax.bar_label(container, fmt='%d', label_type='edge', fontsize=9, padding=2)\n",
    "\n",
    "    plt.title(f'Count of {col}', fontsize=12)\n",
    "    plt.xlabel(col)\n",
    "    plt.ylabel(\"Count\")\n",
    "    plt.xticks(rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a946ac6",
   "metadata": {},
   "source": [
    "## Bivariate Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0420a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Correlation Matrix of numerical columns\n",
    "from pandas.api.types import CategoricalDtype\n",
    "\n",
    "# 1) Define ORDERS (lowest → highest)\n",
    "ship_mode_order = [\n",
    "    \"Standard Class\",\n",
    "    \"Same Day\",\n",
    "    \"Second Class\",\n",
    "    \"First Class\",\n",
    "]\n",
    "\n",
    "segment_order = [\n",
    "    \"Consumer\",\n",
    "    \"Home Office\",\n",
    "    \"Corporate\",\n",
    "]\n",
    "\n",
    "category_order = [\n",
    "    \"Furniture\",\n",
    "    \"Office Supplies\",\n",
    "    \"Technology\",\n",
    "]\n",
    "\n",
    "# 2) Encode ordinals → integer scores (NaN if unknown/missing)\n",
    "df_enc = current_df.copy()\n",
    "\n",
    "ord_specs = {\n",
    "    \"ship_mode\": ship_mode_order,\n",
    "    \"segment\": segment_order,\n",
    "    \"category\": category_order,\n",
    "}\n",
    "\n",
    "encoded_cols = []\n",
    "for col, order in ord_specs.items():\n",
    "    # set ordered categorical\n",
    "    ctype = CategoricalDtype(categories=order, ordered=True)\n",
    "    df_enc[col] = df_enc[col].astype(str).where(df_enc[col].notna(), np.nan)  # preserve NaN\n",
    "    df_enc[col] = df_enc[col].astype(ctype)\n",
    "    # create numeric code column (keep NaN where category missing)\n",
    "    new_col = f\"{col}_ord\"\n",
    "    codes = df_enc[col].cat.codes.replace(-1, np.nan)\n",
    "    df_enc[new_col] = codes\n",
    "    encoded_cols.append(new_col)\n",
    "\n",
    "# 3) Build list of numeric columns (original numerics + encoded ordinals)\n",
    "num_cols_final = list(df_enc.select_dtypes(include=[np.number]).columns)\n",
    "\n",
    "# If you only want your existing numerical_cols + the encoded ordinals:\n",
    "num_cols_final = [c for c in numerical_cols if c in df_enc.columns] + encoded_cols\n",
    "\n",
    "# 4) Spearman correlation (handles monotonic ordinal relationships)\n",
    "corr = df_enc[num_cols_final].corr(method=\"spearman\")\n",
    "\n",
    "# 5) Plot heatmap (upper triangle)\n",
    "mask = np.triu(np.ones_like(corr, dtype=bool))\n",
    "plt.figure(figsize=(10, 12))\n",
    "sns.heatmap(corr, mask=mask, annot=True, cmap=\"coolwarm\", fmt=\".2f\", square=True,\n",
    "            cbar_kws={\"shrink\": .8}, linewidths=.5)\n",
    "plt.title(\"Correlation Matrix: Numerical + Encoded Ordinals (Spearman)\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f93af9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Scatter plots for pairwise numerical columns\n",
    "\n",
    "# Generate all unique pairs of numerical columns\n",
    "pairs = list(itertools.combinations(numerical_cols, 2))\n",
    "\n",
    "# Determine grid layout automatically\n",
    "cols = 2\n",
    "rows = int(np.ceil(len(pairs) / cols))\n",
    "\n",
    "plt.figure(figsize=(12, 4 * rows))\n",
    "\n",
    "for i, (x_col, y_col) in enumerate(pairs, 1):\n",
    "    # Capitalize column names for display\n",
    "    x_display = str.capitalize(x_col)\n",
    "    y_display = str.capitalize(y_col)\n",
    "    plt.subplot(rows, cols, i)\n",
    "    sns.scatterplot(data=current_df, x=x_col, y=y_col, color='steelblue', edgecolor='k', alpha=0.7)\n",
    "    plt.title(f'{y_display} vs {x_display}')\n",
    "    plt.xlabel(x_display)\n",
    "    plt.ylabel(y_display)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77d820a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Create box plots for categorical columns vs. numerical columns\n",
    "\n",
    "# Exclude columns if needed\n",
    "exclude_cat = ['country/region','city']  \n",
    "exclude_num = ['discount']\n",
    "used_cat = [col for col in categorical_cols if col not in exclude_cat]\n",
    "used_num = [col for col in numerical_cols if col not in exclude_num]\n",
    "\n",
    "# Set up plot grid\n",
    "cols = 2                # number of boxplots per row\n",
    "row_height = 4          # adjust height for spacing\n",
    "\n",
    "for cat_col in used_cat:\n",
    "    rows = int(np.ceil(len(used_num) / cols))\n",
    "    plt.figure(figsize=(14, row_height * rows))\n",
    "\n",
    "    for j, num_col in enumerate(used_num, 1):\n",
    "        plt.subplot(rows, cols, j)\n",
    "\n",
    "        cat_display = str.capitalize(cat_col)\n",
    "        num_display = str.capitalize(num_col)\n",
    "\n",
    "        order = current_df[cat_col].value_counts().index[:10]  # limit categories\n",
    "\n",
    "        sns.boxplot(\n",
    "            data=current_df,\n",
    "            y=cat_col,\n",
    "            x=num_col,\n",
    "            order=order\n",
    "        )\n",
    "\n",
    "        plt.title(f'{num_display}', fontsize=11, fontweight='bold')\n",
    "        plt.xlabel(cat_display)\n",
    "        plt.ylabel(num_display)\n",
    "        plt.xticks(rotation=45)\n",
    "\n",
    "    plt.suptitle(f'Boxplots grouped by {cat_col}', y=1.02, fontsize=14, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd9d7f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Create bar plots for categorical columns vs. sum of numerical columns\n",
    "# Exclude columns if needed\n",
    "exclude_cat = ['country/region','city']  \n",
    "exclude_num = []\n",
    "used_cat = [col for col in categorical_cols if col not in exclude_cat]\n",
    "used_num = [col for col in numerical_cols if col not in exclude_num]\n",
    "\n",
    "# Set up plot grid\n",
    "cols = 2                # number of bar plots per row\n",
    "row_height = 4          # adjust height for spacing\n",
    "\n",
    "for cat_col in used_cat:\n",
    "    rows = int(np.ceil(len(used_num) / cols))\n",
    "    plt.figure(figsize=(14, row_height * rows))\n",
    "\n",
    "    for j, num_col in enumerate(used_num, 1):\n",
    "        plt.subplot(rows, cols, j)\n",
    "\n",
    "        cat_display = str.capitalize(cat_col)\n",
    "        num_display = str.capitalize(num_col)\n",
    "\n",
    "        order = current_df[cat_col].value_counts().index[:10]  # limit categories\n",
    "\n",
    "        ax = sns.barplot(\n",
    "            data=current_df,\n",
    "            y=cat_col,\n",
    "            x=num_col,\n",
    "            order=order,\n",
    "            estimator=np.nansum,\n",
    "            errorbar=None\n",
    "        )\n",
    "\n",
    "        # --- Add data labels ---\n",
    "        for container in ax.containers:\n",
    "            ax.bar_label(container, fmt='%d', label_type='edge', fontsize=9, padding=2)\n",
    "\n",
    "        plt.title(f'{num_display}', fontsize=11, fontweight='bold')\n",
    "        plt.xlabel(f'Sum of {num_display}') # x is the total\n",
    "        plt.ylabel(num_display)\n",
    "        plt.xticks(rotation=0)\n",
    "\n",
    "    plt.suptitle(f'Barplots grouped by {cat_col}', y=1.02, fontsize=14, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25b66d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Create a pair plot of the numerical columns\n",
    "# Exclude columns if needed\n",
    "exclude_cat = ['country/region','city','state']  \n",
    "exclude_num = ['discount']\n",
    "used_cat = [col for col in categorical_cols if col not in exclude_cat]\n",
    "used_num = [col for col in numerical_cols if col not in exclude_num]\n",
    "\n",
    "# Create pairplot\n",
    "sns.pairplot(current_df[used_num], diag_kind='kde', markers='o')\n",
    "plt.suptitle('Pair Plot of Numerical Columns', y=1.02)\n",
    "plt.show()\n",
    "\n",
    "# 2. Create a pair plot of numerical columns colored by a categorical column\n",
    "for cat_col in used_cat:\n",
    "    if current_df[cat_col].nunique() > 10:\n",
    "        print(f\"⚠️ Categorical column '{cat_col}' has more than 10 unique values, skipping pair plot.\")\n",
    "        continue\n",
    "    sns.pairplot(current_df, vars=used_num, hue=cat_col, diag_kind='kde', markers='o')\n",
    "    plt.suptitle(f'Pair Plot of Numerical Columns colored by {cat_col}', y=1.02)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f94ed6ff",
   "metadata": {},
   "source": [
    "## Export Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ce834a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop redundant columns containing outlier flags if any\n",
    "outlier_flag_cols = [col for col in current_df.columns if 'outlier' in col.lower()]\n",
    "for col in outlier_flag_cols:\n",
    "    current_df.drop(columns=[col], inplace=True)\n",
    "    print(f\"✅ Dropped outlier flag column: {col}\")\n",
    "    \n",
    "# Overwrite original dataframe with current dataframe\n",
    "superstore_df = current_df.copy()\n",
    "print(\"✅ Overwrote 'superstore_df' with current dataframe.\")\n",
    "\n",
    "\n",
    "# Export Data\n",
    "superstore_df.to_csv('superstore_data_cleaned.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
